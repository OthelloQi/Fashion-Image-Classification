
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DSVM to run a Deep learning Keras model to classify fashion items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You created a fashion classification model in [Microsoft Custom Vision service](https://www.customvision.ai/) via UI and in python code. However if you need to start building your own custom code Deep Neural Networks - [Keras](https://keras.io/) is a great high level API to use to do this.\n",
    "\n",
    "In the code below we build a model from the Fashion MNIST dataset to classify clothing items into 10 categories. The data can be found here: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "Because we are using the DSVM, all packages and frameworks are already installed on the machine. So we only need to import the package we need! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import Tensorflow framework and Keras. As well as other more basic python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can change the backend used in Keras from Tensorflow to CNTK by simply changing the `os.environ['KERAS_BACKEND']` variable to `cntk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-21423611b1cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TF_CPP_MIN_LOG_LEVEL\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"2\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tensorflow Version is: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "print(\"tensorflow Version is: \" + str(tf.__version__))\n",
    "\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "print(os.environ['KERAS_BACKEND'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import all the Keras functions we will need to use to create a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import utils, losses, optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We setup some variables for example how many classes there are [0-9] as well as batch size to send the training sample of data in to the model and epochs is how many iterations/run thoroughs of the data there are\n",
    "* Each image is of size 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no. of classes\n",
    "num_classes = 10\n",
    "\n",
    "# batch size and training iterations (epochs)\n",
    "batch_size = 128\n",
    "epochs = 24\n",
    "\n",
    "#input image dimensions\n",
    "img_rows,img_cols = 28,28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section lets have a look at the data\n",
    "* we pull in the fashion MNIST data from the Keras library into training and testing sets\n",
    "* X stands for features and y stands for labels\n",
    "* From the shape statements in the output you can see there are 60,000! training images and 10,000 test images - so a lot more data to use in this model\n",
    "* We then show one of the images from the training set and the corresponding text label for the image\n",
    "\n",
    "> change the img_index field to any number between 0 - 60000 to see different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) train set\n",
      "(10000, 28, 28) test set\n",
      "Label Index: 9 Fashion Labels: Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data for train and testing\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(x_train.shape, 'train set')\n",