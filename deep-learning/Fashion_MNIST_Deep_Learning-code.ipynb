
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DSVM to run a Deep learning Keras model to classify fashion items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You created a fashion classification model in [Microsoft Custom Vision service](https://www.customvision.ai/) via UI and in python code. However if you need to start building your own custom code Deep Neural Networks - [Keras](https://keras.io/) is a great high level API to use to do this.\n",
    "\n",
    "In the code below we build a model from the Fashion MNIST dataset to classify clothing items into 10 categories. The data can be found here: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "Because we are using the DSVM, all packages and frameworks are already installed on the machine. So we only need to import the package we need! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import Tensorflow framework and Keras. As well as other more basic python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can change the backend used in Keras from Tensorflow to CNTK by simply changing the `os.environ['KERAS_BACKEND']` variable to `cntk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
    "print(\"tensorflow Version is: \" + str(tf.__version__))\n",
    "\n",
    "import numpy as np\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "print(os.environ['KERAS_BACKEND'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import all the Keras functions we will need to use to create a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import utils, losses, optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We setup some variables for example how many classes there are [0-9] as well as batch size to send the training sample of data in to the model and epochs is how many iterations/run thoroughs of the data there are\n",
    "* Each image is of size 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no. of classes\n",
    "num_classes = 10\n",
    "\n",
    "# batch size and training iterations (epochs)\n",
    "batch_size = 128\n",
    "epochs = 24\n",
    "\n",
    "#input image dimensions\n",
    "img_rows,img_cols = 28,28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section lets have a look at the data\n",
    "* we pull in the fashion MNIST data from the Keras library into training and testing sets\n",
    "* X stands for features and y stands for labels\n",
    "* From the shape statements in the output you can see there are 60,000! training images and 10,000 test images - so a lot more data to use in this model\n",
    "* We then show one of the images from the training set and the corresponding text label for the image\n",
    "\n",
    "> change the img_index field to any number between 0 - 60000 to see different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data for train and testing\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(x_train.shape, 'train set')\n",
    "print(x_test.shape, 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"Top\",          # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Jumper\",       # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Trainer\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "img_index=90\n",
    "label_index = y_train[img_index]\n",
    "plt.imshow(x_train[img_index])\n",
    "print('Label Index: ' + str(label_index) + \" Fashion Labels: \" + (fashion_mnist_labels[label_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section we normalise the data so the pixel values in the image are between 0 - 1 instead of 0 - 255 pixel values. This will help the model to converge and the math becomes easier with smaller numbers\n",
    "* We also [one-hot-encode](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science#) the labels in matrices with 0's and 1's in them only. We do this so the model does not deem any category 0-9 in a numeric ranking. For example it won't think that tshirts[0] always come before trousers[1] when actually these are IDs of the classes not something to be evaluated\n",
    "* finally as we are deadling with greyscale images we have a depth number = 1 that might be interpreted different dpending on the framework used (CNTK, Tensorflow etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type convert and scale the test and training data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#one-hot encoding\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test,  num_classes)\n",
    "\n",
    "#formatting issues for depth of image (greyscale = 1) with different kernels (tensorflow, cntk, etc)\n",
    "if K.image_data_format()== 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n",
    "    input_shape = (img_rows, img_cols,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are able to define the Convolutional Neural Network (CNN) in layers\n",
    "\n",
    "![CNN](cnn.JPG \"CNN\")\n",
    "\n",
    "* This is a **sequential model** meaning every layer passes information forward to the next layer of the network\n",
    "* **1st Convoltuional Layer** - extracts features from data source, these are kernels/filters and feature maps. Feature maps passed to the  next layer. This layer also has a ReLu activation function - Y = max(0, x) this removes any value <0 and prevents vanishing gradients or weights <0\n",
    "* **2nd pooling layer ** - reduces dimensionality, reduce compute and helps with overfitting of the data.\n",
    "* **3rd Convolutional Layer ** -we add a Convoltuional Layer - extracts features from data source, these are kernels/filters and feature maps. Feature maps passed to the  next layer. This layer also has a ReLu activation function - Y = max(0, x) this removes any value <0 and prevents vanishing gradients or weights <0\n",
    "* **4th Pooling Layer ** - reduces dimensionality, reduce compute and helps with overfitting of the data.\n",
    "* **5th/6th Dense fully connected layer with softmax function:** put features together and classify what item of clothing is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Run some experiments to see how when you change the model below and rerun all the code the accuarcy and model will change:**\n",
    "* add a dropout layer after the first pooling layer and also before the final dense layer: `model.add(Dropout(0.5))`\n",
    "* change the value of dropout between 0 and 1: `model.add(Dropout(X))`\n",
    "* change the 2 Conv2D layer first variable to 32 instead of 64: `model.add(Conv2D(32, kernel_size=(3,3), activation = 'relu'))`\n",
    "* Add padding to each of the Conv2D layers: `model.add(Conv2D(32, kernel_size=(3,3), padding = 'same', activation = 'relu'))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu'))\n",